# Although patroni does indeed create the configmaps, I wanted to have more control over it within helm during deployment so added both
# the -config and the -leader configmaps manually through helm. These configs allow helm can control the configs during a distroy.
# it also has the advantage of allowing me to use the same template for both Gold and GoldDR which have differing configs.
---
kind: ConfigMap
apiVersion: v1
metadata:
  name: {{ .Values.app_name }}-leader
  namespace: {{ .Values.license_plate }}-dev
  labels:
    app.kubernetes.io/name: {{ .Values.app_name }}
    cluster-name: {{ .Values.app_name }}
---
# It should be noted here that the config is the same for Gold and GoldDR.  There is however a JOB that is run on "install" by helm that
# will override this configmap with the appropriate settings.  This is done mostly to deal with the fact that at helm init we don't
# know the port number for the TCS and can really only determine it at runtime.
kind: ConfigMap
apiVersion: v1
metadata:
  name: {{ .Values.app_name }}-config
  namespace: {{ .Values.license_plate }}-dev
  labels:
    app.kubernetes.io/name: {{ .Values.app_name }}
    cluster-name: {{ .Values.app_name }}
  annotations:
    config: >-
      {"postgresql":{"use_pg_rewind":true,"parameters":{"max_connections":100,"max_prepared_transactions":0,"max_locks_per_transaction":64}}}
---
# this is the entrypoint script that will override the default one in the ppatroni-postgres image.
# TODO: update the code in the upstream image to include hardcoding the 10.95 and 10.97 ranges for the pghba
kind: ConfigMap
apiVersion: v1
metadata:
  name: config-{{ .Values.app_name }}-entrypoint
  namespace: {{ .Values.license_plate }}-dev
  labels:
    app.kubernetes.io/name: {{ .Values.app_name }}
    cluser-name: {{ .Values.app_name }}
data:
  entrypoint.sh: |-
    #!/bin/bash

    if [[ $UID -ge 10000 ]]; then
        GID=$(id -g)
        sed -e "s/^postgres:x:[^:]*:[^:]*:/postgres:x:$UID:$GID:/" /etc/passwd > /tmp/passwd
        cat /tmp/passwd > /etc/passwd
        rm /tmp/passwd
    fi

    # FIX -> FATAL:  data directory "..." has group or world access
    mkdir -p "$PATRONI_POSTGRESQL_DATA_DIR"
    chmod 700 "$PATRONI_POSTGRESQL_DATA_DIR"

    cat > /home/postgres/patroni.yml <<__EOF__
    bootstrap:
      post_bootstrap: /usr/share/scripts/patroni/post_init.sh
      dcs:
        postgresql:
          use_pg_rewind: true
          parameters:
            max_connections: ${POSTGRESQL_MAX_CONNECTIONS:-100}
            max_prepared_transactions: ${POSTGRESQL_MAX_PREPARED_TRANSACTIONS:-0}
            max_locks_per_transaction: ${POSTGRESQL_MAX_LOCKS_PER_TRANSACTION:-64}
      initdb:
      - auth-host: md5
      - auth-local: trust
      - encoding: UTF8
      - locale: en_US.UTF-8
      - data-checksums
      pg_hba:
      - host all all 0.0.0.0/0 md5
      - host replication ${PATRONI_REPLICATION_USERNAME} 10.95.0.0/16    md5  # GoldDR Range
      - host replication ${PATRONI_REPLICATION_USERNAME} 10.97.0.0/16    md5  # Gold & Silver Clusters
    restapi:
      connect_address: '${POD_IP}:8008'
    postgresql:
      connect_address: '${POD_IP}:5432'
      authentication:
        superuser:
          password: '${PATRONI_SUPERUSER_PASSWORD}'
        replication:
          password: '${PATRONI_REPLICATION_PASSWORD}'
    __EOF__

    unset PATRONI_SUPERUSER_PASSWORD PATRONI_REPLICATION_PASSWORD
    export KUBERNETES_NAMESPACE=$PATRONI_KUBERNETES_NAMESPACE
    export POD_NAME=$PATRONI_NAME

    exec /usr/bin/python3 /usr/local/bin/patroni /home/postgres/patroni.yml
---